{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wineQuality.ipynb  wineQuality.py\twinequality-white.csv\r\n",
      "winequality.names  winequality-red.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Citation Request:\r",
      "\r\n",
      "  This dataset is public available for research. The details are described in [Cortez et al., 2009]. \r",
      "\r\n",
      "  Please include this citation if you plan to use this database:\r",
      "\r\n",
      "\r",
      "\r\n",
      "  P. Cortez, A. Cerdeira, F. Almeida, T. Matos and J. Reis. \r",
      "\r\n",
      "  Modeling wine preferences by data mining from physicochemical properties.\r",
      "\r\n",
      "  In Decision Support Systems, Elsevier, 47(4):547-553. ISSN: 0167-9236.\r",
      "\r\n",
      "\r",
      "\r\n",
      "  Available at: [@Elsevier] http://dx.doi.org/10.1016/j.dss.2009.05.016\r",
      "\r\n",
      "                [Pre-press (pdf)] http://www3.dsi.uminho.pt/pcortez/winequality09.pdf\r",
      "\r\n",
      "                [bib] http://www3.dsi.uminho.pt/pcortez/dss09.bib\r",
      "\r\n",
      "\r",
      "\r\n",
      "1. Title: Wine Quality \r",
      "\r\n",
      "\r",
      "\r\n",
      "2. Sources\r",
      "\r\n",
      "   Created by: Paulo Cortez (Univ. Minho), Antonio Cerdeira, Fernando Almeida, Telmo Matos and Jose Reis (CVRVV) @ 2009\r",
      "\r\n",
      "   \r",
      "\r\n",
      "3. Past Usage:\r",
      "\r\n",
      "\r",
      "\r\n",
      "  P. Cortez, A. Cerdeira, F. Almeida, T. Matos and J. Reis. \r",
      "\r\n",
      "  Modeling wine preferences by data mining from physicochemical properties.\r",
      "\r\n",
      "  In Decision Support Systems, Elsevier, 47(4):547-553. ISSN: 0167-9236.\r",
      "\r\n",
      "\r",
      "\r\n",
      "  In the above reference, two datasets were created, using red and white wine samples.\r",
      "\r\n",
      "  The inputs include objective tests (e.g. PH values) and the output is based on sensory data\r",
      "\r\n",
      "  (median of at least 3 evaluations made by wine experts). Each expert graded the wine quality \r",
      "\r\n",
      "  between 0 (very bad) and 10 (very excellent). Several data mining methods were applied to model\r",
      "\r\n",
      "  these datasets under a regression approach. The support vector machine model achieved the\r",
      "\r\n",
      "  best results. Several metrics were computed: MAD, confusion matrix for a fixed error tolerance (T),\r",
      "\r\n",
      "  etc. Also, we plot the relative importances of the input variables (as measured by a sensitivity\r",
      "\r\n",
      "  analysis procedure).\r",
      "\r\n",
      " \r",
      "\r\n",
      "4. Relevant Information:\r",
      "\r\n",
      "\r",
      "\r\n",
      "   The two datasets are related to red and white variants of the Portuguese \"Vinho Verde\" wine.\r",
      "\r\n",
      "   For more details, consult: http://www.vinhoverde.pt/en/ or the reference [Cortez et al., 2009].\r",
      "\r\n",
      "   Due to privacy and logistic issues, only physicochemical (inputs) and sensory (the output) variables \r",
      "\r\n",
      "   are available (e.g. there is no data about grape types, wine brand, wine selling price, etc.).\r",
      "\r\n",
      "\r",
      "\r\n",
      "   These datasets can be viewed as classification or regression tasks.\r",
      "\r\n",
      "   The classes are ordered and not balanced (e.g. there are munch more normal wines than\r",
      "\r\n",
      "   excellent or poor ones). Outlier detection algorithms could be used to detect the few excellent\r",
      "\r\n",
      "   or poor wines. Also, we are not sure if all input variables are relevant. So\r",
      "\r\n",
      "   it could be interesting to test feature selection methods. \r",
      "\r\n",
      "\r",
      "\r\n",
      "5. Number of Instances: red wine - 1599; white wine - 4898. \r",
      "\r\n",
      "\r",
      "\r\n",
      "6. Number of Attributes: 11 + output attribute\r",
      "\r\n",
      "  \r",
      "\r\n",
      "   Note: several of the attributes may be correlated, thus it makes sense to apply some sort of\r",
      "\r\n",
      "   feature selection.\r",
      "\r\n",
      "\r",
      "\r\n",
      "7. Attribute information:\r",
      "\r\n",
      "\r",
      "\r\n",
      "   For more information, read [Cortez et al., 2009].\r",
      "\r\n",
      "\r",
      "\r\n",
      "   Input variables (based on physicochemical tests):\r",
      "\r\n",
      "   1 - fixed acidity\r",
      "\r\n",
      "   2 - volatile acidity\r",
      "\r\n",
      "   3 - citric acid\r",
      "\r\n",
      "   4 - residual sugar\r",
      "\r\n",
      "   5 - chlorides\r",
      "\r\n",
      "   6 - free sulfur dioxide\r",
      "\r\n",
      "   7 - total sulfur dioxide\r",
      "\r\n",
      "   8 - density\r",
      "\r\n",
      "   9 - pH\r",
      "\r\n",
      "   10 - sulphates\r",
      "\r\n",
      "   11 - alcohol\r",
      "\r\n",
      "   Output variable (based on sensory data): \r",
      "\r\n",
      "   12 - quality (score between 0 and 10)\r",
      "\r\n",
      "\r",
      "\r\n",
      "8. Missing Attribute Values: None\r",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!cat winequality.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "whiteWine = pd.read_csv('winequality-white.csv',delimiter=';')\n",
    "#whiteWine['wine']=1\n",
    "redWine = pd.read_csv('winequality-red.csv',delimiter=';')\n",
    "#redWine['wine']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "wines = pd.concat([whiteWine,redWine], axis=0, sort=False)\n",
    "wines = shuffle(wines)\n",
    "wines.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6497, 12)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wines.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4898, 12), (1599, 12))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whiteWine.shape, redWine.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.5</td>\n",
       "      <td>0.650</td>\n",
       "      <td>0.18</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.088</td>\n",
       "      <td>27.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>0.99915</td>\n",
       "      <td>3.38</td>\n",
       "      <td>0.77</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.9</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.24</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.057</td>\n",
       "      <td>13.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.99420</td>\n",
       "      <td>2.99</td>\n",
       "      <td>0.48</td>\n",
       "      <td>9.5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.3</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.20</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.080</td>\n",
       "      <td>27.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>0.99720</td>\n",
       "      <td>3.16</td>\n",
       "      <td>1.12</td>\n",
       "      <td>9.1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.7</td>\n",
       "      <td>0.460</td>\n",
       "      <td>0.46</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.040</td>\n",
       "      <td>31.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>0.99320</td>\n",
       "      <td>3.13</td>\n",
       "      <td>0.47</td>\n",
       "      <td>8.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.6</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0.26</td>\n",
       "      <td>11.1</td>\n",
       "      <td>0.030</td>\n",
       "      <td>43.5</td>\n",
       "      <td>171.0</td>\n",
       "      <td>0.99480</td>\n",
       "      <td>3.03</td>\n",
       "      <td>0.49</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.35</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.088</td>\n",
       "      <td>16.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.99610</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.55</td>\n",
       "      <td>9.2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.9</td>\n",
       "      <td>0.320</td>\n",
       "      <td>0.26</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.030</td>\n",
       "      <td>11.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>0.99106</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.42</td>\n",
       "      <td>11.1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9.1</td>\n",
       "      <td>0.470</td>\n",
       "      <td>0.49</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.094</td>\n",
       "      <td>38.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>0.99820</td>\n",
       "      <td>3.08</td>\n",
       "      <td>0.59</td>\n",
       "      <td>9.1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>11.4</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0.44</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.071</td>\n",
       "      <td>6.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.99860</td>\n",
       "      <td>3.12</td>\n",
       "      <td>0.82</td>\n",
       "      <td>9.3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8.7</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.226</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.99910</td>\n",
       "      <td>3.32</td>\n",
       "      <td>0.60</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.5             0.650         0.18             7.0      0.088   \n",
       "1            6.9             0.250         0.24             3.6      0.057   \n",
       "2            8.3             0.625         0.20             1.5      0.080   \n",
       "3            5.7             0.460         0.46             1.4      0.040   \n",
       "4            8.6             0.360         0.26            11.1      0.030   \n",
       "5            7.0             0.420         0.35             1.6      0.088   \n",
       "6            6.9             0.320         0.26             2.3      0.030   \n",
       "7            9.1             0.470         0.49             2.6      0.094   \n",
       "8           11.4             0.260         0.44             3.6      0.071   \n",
       "9            8.7             0.700         0.24             2.5      0.226   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 27.0                  94.0  0.99915  3.38       0.77   \n",
       "1                 13.0                  85.0  0.99420  2.99       0.48   \n",
       "2                 27.0                 119.0  0.99720  3.16       1.12   \n",
       "3                 31.0                 169.0  0.99320  3.13       0.47   \n",
       "4                 43.5                 171.0  0.99480  3.03       0.49   \n",
       "5                 16.0                  39.0  0.99610  3.34       0.55   \n",
       "6                 11.0                 103.0  0.99106  3.06       0.42   \n",
       "7                 38.0                 106.0  0.99820  3.08       0.59   \n",
       "8                  6.0                  19.0  0.99860  3.12       0.82   \n",
       "9                  5.0                  15.0  0.99910  3.32       0.60   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        5  \n",
       "1      9.5        4  \n",
       "2      9.1        4  \n",
       "3      8.8        5  \n",
       "4     12.0        5  \n",
       "5      9.2        5  \n",
       "6     11.1        6  \n",
       "7      9.1        5  \n",
       "8      9.3        6  \n",
       "9      9.0        6  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wines.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "quality = wines['quality']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.5</td>\n",
       "      <td>0.650</td>\n",
       "      <td>0.18</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.088</td>\n",
       "      <td>27.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>0.99915</td>\n",
       "      <td>3.38</td>\n",
       "      <td>0.77</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.9</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.24</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.057</td>\n",
       "      <td>13.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.99420</td>\n",
       "      <td>2.99</td>\n",
       "      <td>0.48</td>\n",
       "      <td>9.5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.3</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.20</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.080</td>\n",
       "      <td>27.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>0.99720</td>\n",
       "      <td>3.16</td>\n",
       "      <td>1.12</td>\n",
       "      <td>9.1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.7</td>\n",
       "      <td>0.460</td>\n",
       "      <td>0.46</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.040</td>\n",
       "      <td>31.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>0.99320</td>\n",
       "      <td>3.13</td>\n",
       "      <td>0.47</td>\n",
       "      <td>8.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.6</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0.26</td>\n",
       "      <td>11.1</td>\n",
       "      <td>0.030</td>\n",
       "      <td>43.5</td>\n",
       "      <td>171.0</td>\n",
       "      <td>0.99480</td>\n",
       "      <td>3.03</td>\n",
       "      <td>0.49</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.5             0.650         0.18             7.0      0.088   \n",
       "1            6.9             0.250         0.24             3.6      0.057   \n",
       "2            8.3             0.625         0.20             1.5      0.080   \n",
       "3            5.7             0.460         0.46             1.4      0.040   \n",
       "4            8.6             0.360         0.26            11.1      0.030   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 27.0                  94.0  0.99915  3.38       0.77   \n",
       "1                 13.0                  85.0  0.99420  2.99       0.48   \n",
       "2                 27.0                 119.0  0.99720  3.16       1.12   \n",
       "3                 31.0                 169.0  0.99320  3.13       0.47   \n",
       "4                 43.5                 171.0  0.99480  3.03       0.49   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        5  \n",
       "1      9.5        4  \n",
       "2      9.1        4  \n",
       "3      8.8        5  \n",
       "4     12.0        5  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wines.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocess and analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6487</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.49</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.037</td>\n",
       "      <td>33.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>0.99200</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.54</td>\n",
       "      <td>11.1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6488</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.24</td>\n",
       "      <td>6.1</td>\n",
       "      <td>0.032</td>\n",
       "      <td>19.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>0.98934</td>\n",
       "      <td>3.04</td>\n",
       "      <td>0.26</td>\n",
       "      <td>13.4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6489</th>\n",
       "      <td>6.8</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.23</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0.026</td>\n",
       "      <td>31.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>0.98960</td>\n",
       "      <td>3.10</td>\n",
       "      <td>0.40</td>\n",
       "      <td>12.4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6490</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.19</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.043</td>\n",
       "      <td>17.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>0.99438</td>\n",
       "      <td>3.67</td>\n",
       "      <td>0.57</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6491</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.032</td>\n",
       "      <td>12.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.99286</td>\n",
       "      <td>3.25</td>\n",
       "      <td>0.36</td>\n",
       "      <td>8.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6492</th>\n",
       "      <td>6.7</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.26</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.079</td>\n",
       "      <td>35.5</td>\n",
       "      <td>216.0</td>\n",
       "      <td>0.99560</td>\n",
       "      <td>3.31</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6493</th>\n",
       "      <td>6.5</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.19</td>\n",
       "      <td>6.6</td>\n",
       "      <td>0.045</td>\n",
       "      <td>98.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>0.99364</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.34</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6494</th>\n",
       "      <td>7.7</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.044</td>\n",
       "      <td>29.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>0.99312</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.56</td>\n",
       "      <td>10.6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6495</th>\n",
       "      <td>5.7</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.28</td>\n",
       "      <td>3.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>57.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>0.99130</td>\n",
       "      <td>3.22</td>\n",
       "      <td>0.27</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6496</th>\n",
       "      <td>7.6</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.34</td>\n",
       "      <td>9.7</td>\n",
       "      <td>0.035</td>\n",
       "      <td>26.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>0.99650</td>\n",
       "      <td>3.08</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "6487            7.4              0.27         0.49             1.1      0.037   \n",
       "6488            6.2              0.37         0.24             6.1      0.032   \n",
       "6489            6.8              0.32         0.23             3.3      0.026   \n",
       "6490            5.0              0.24         0.19             5.0      0.043   \n",
       "6491            5.9              0.54         0.00             0.8      0.032   \n",
       "6492            6.7              0.26         0.26             4.0      0.079   \n",
       "6493            6.5              0.27         0.19             6.6      0.045   \n",
       "6494            7.7              0.28         0.24             2.4      0.044   \n",
       "6495            5.7              0.15         0.28             3.7      0.045   \n",
       "6496            7.6              0.22         0.34             9.7      0.035   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "6487                 33.0                 156.0  0.99200  3.15       0.54   \n",
       "6488                 19.0                  86.0  0.98934  3.04       0.26   \n",
       "6489                 31.0                  99.0  0.98960  3.10       0.40   \n",
       "6490                 17.0                 101.0  0.99438  3.67       0.57   \n",
       "6491                 12.0                  82.0  0.99286  3.25       0.36   \n",
       "6492                 35.5                 216.0  0.99560  3.31       0.68   \n",
       "6493                 98.0                 175.0  0.99364  3.16       0.34   \n",
       "6494                 29.0                 157.0  0.99312  3.27       0.56   \n",
       "6495                 57.0                 151.0  0.99130  3.22       0.27   \n",
       "6496                 26.0                 143.0  0.99650  3.08       0.49   \n",
       "\n",
       "      alcohol  quality  \n",
       "6487     11.1        6  \n",
       "6488     13.4        8  \n",
       "6489     12.4        6  \n",
       "6490     10.0        5  \n",
       "6491      8.8        5  \n",
       "6492      9.5        5  \n",
       "6493     10.1        6  \n",
       "6494     10.6        6  \n",
       "6495     11.2        6  \n",
       "6496      9.8        6  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wines.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fixed acidity           0\n",
       "volatile acidity        0\n",
       "citric acid             0\n",
       "residual sugar          0\n",
       "chlorides               0\n",
       "free sulfur dioxide     0\n",
       "total sulfur dioxide    0\n",
       "density                 0\n",
       "pH                      0\n",
       "sulphates               0\n",
       "alcohol                 0\n",
       "quality                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wines.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = list(wines.columns)\n",
    "op = 'quality'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_dict = {}\n",
    "for i in range(0,len(columns)):\n",
    "    if op != columns[i]:\n",
    "        corr_dict['{}'.format(columns[i])] = whiteWine[columns[i]].corr(whiteWine[op])\n",
    "        \n",
    "corr_dict = dict(sorted(corr_dict.items(), key=lambda item: abs(item[1]), reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alcohol': 0.4355747154613735,\n",
       " 'density': -0.30712331273472987,\n",
       " 'chlorides': -0.20993441094676066,\n",
       " 'volatile acidity': -0.19472296892113433,\n",
       " 'total sulfur dioxide': -0.17473721759706282,\n",
       " 'fixed acidity': -0.11366283071301793,\n",
       " 'pH': 0.09942724573666419,\n",
       " 'residual sugar': -0.09757682889469317,\n",
       " 'sulphates': 0.05367787713279209,\n",
       " 'citric acid': -0.009209090883975429,\n",
       " 'free sulfur dioxide': 0.008158067123436068}"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fixed acidity', 'volatile acidity', 'residual sugar', 'chlorides', 'total sulfur dioxide', 'density', 'pH', 'sulphates', 'alcohol']\n"
     ]
    }
   ],
   "source": [
    "thresh = 0.05\n",
    "features = []\n",
    "for i in columns:\n",
    "    if i!=op and abs(corr_dict[i])>=thresh:\n",
    "        features.append(i)\n",
    "        \n",
    "print(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Findings from this:\n",
    "No significant correlation between any values with quality. A bit with amount of alcohol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_features = whiteWine[features]\n",
    "wine_quality = whiteWine[op]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(wine_features, wine_quality, test_size=0.33, random_state=42)\n",
    "\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "base = LinearRegression()\n",
    "base.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.4459684  5.63494681 6.52294918 ... 6.17498877 6.2051246  5.83936611]\n",
      "[6.33274077 6.38031476 6.41642005 ... 5.8959915  6.0091014  5.79396424]\n"
     ]
    }
   ],
   "source": [
    "train_pred = base.predict(X_train)\n",
    "print(train_pred)\n",
    "test_pred = base.predict(X_test) \n",
    "print(test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7553222838680139\n",
      "0.7463493602535066\n",
      "[6. 6. 6. ... 6. 6. 6.]\n",
      "Mean Absolute Error: 0.5827222658263003\n",
      "Mean Squared Error: 0.5570373675508186\n",
      "Root Mean Squared Error: 0.7463493602535066\n",
      "                      Coeffecient\n",
      "fixed acidity            0.041819\n",
      "volatile acidity        -0.205179\n",
      "residual sugar           0.433248\n",
      "chlorides                0.005959\n",
      "total sulfur dioxide     0.039440\n",
      "density                 -0.458640\n",
      "pH                       0.104229\n",
      "sulphates                0.082753\n",
      "alcohol                  0.254510\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "# calculating rmse\n",
    "train_rmse = mean_squared_error(train_pred, y_train) ** 0.5\n",
    "print(train_rmse)\n",
    "test_rmse = mean_squared_error(test_pred, y_test) ** 0.5\n",
    "print(test_rmse)# rounding off the predicted values for test set\n",
    "predicted_data = np.round_(test_pred)\n",
    "print(predicted_data)\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, test_pred))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, test_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, test_pred)))# displaying coefficients of each feature\n",
    "coeffecients = pd.DataFrame(base.coef_,features) \n",
    "coeffecients.columns = ['Coeffecient'] \n",
    "print(coeffecients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=len(features),kernel_initializer='he_uniform', activation='relu'))\n",
    "model.add(Dense(64, kernel_initializer='he_uniform', activation='relu'))\n",
    "model.add(Dense(32, kernel_initializer='he_uniform', activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 26.0594 - mae: 4.9587 - val_loss: 19.8109 - val_mae: 4.2601\n",
      "Epoch 2/150\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 14.1361 - mae: 3.4646 - val_loss: 9.3373 - val_mae: 2.7366\n",
      "Epoch 3/150\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 7.0671 - mae: 2.2249 - val_loss: 5.2948 - val_mae: 1.8786\n",
      "Epoch 4/150\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 5.0371 - mae: 1.7455 - val_loss: 4.2470 - val_mae: 1.6193\n",
      "Epoch 5/150\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 4.2228 - mae: 1.5583 - val_loss: 3.6418 - val_mae: 1.4935\n",
      "Epoch 6/150\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 3.6640 - mae: 1.4415 - val_loss: 3.2337 - val_mae: 1.3993\n",
      "Epoch 7/150\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 3.2817 - mae: 1.3584 - val_loss: 2.9510 - val_mae: 1.3385\n",
      "Epoch 8/150\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 2.9983 - mae: 1.3009 - val_loss: 2.7328 - val_mae: 1.2893\n",
      "Epoch 9/150\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 2.7748 - mae: 1.2558 - val_loss: 2.5682 - val_mae: 1.2505\n",
      "Epoch 10/150\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 2.5930 - mae: 1.2165 - val_loss: 2.4322 - val_mae: 1.2133\n",
      "Epoch 11/150\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 2.4517 - mae: 1.1861 - val_loss: 2.3267 - val_mae: 1.1850\n",
      "Epoch 12/150\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 2.3313 - mae: 1.1594 - val_loss: 2.2300 - val_mae: 1.1520\n",
      "Epoch 13/150\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 2.2202 - mae: 1.1328 - val_loss: 2.1456 - val_mae: 1.1310\n",
      "Epoch 14/150\n",
      "72/72 [==============================] - 0s 5ms/step - loss: 2.1239 - mae: 1.1083 - val_loss: 2.0674 - val_mae: 1.1107\n",
      "Epoch 15/150\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 2.0373 - mae: 1.0858 - val_loss: 1.9971 - val_mae: 1.0934\n",
      "Epoch 16/150\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 1.9571 - mae: 1.0689 - val_loss: 1.9371 - val_mae: 1.0738\n",
      "Epoch 17/150\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.8807 - mae: 1.0473 - val_loss: 1.9017 - val_mae: 1.0740\n",
      "Epoch 18/150\n",
      "72/72 [==============================] - 0s 5ms/step - loss: 1.8199 - mae: 1.0330 - val_loss: 1.8205 - val_mae: 1.0418\n",
      "Epoch 19/150\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 1.7539 - mae: 1.0158 - val_loss: 1.7690 - val_mae: 1.0249\n",
      "Epoch 20/150\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 1.6923 - mae: 0.9988 - val_loss: 1.7155 - val_mae: 1.0084\n",
      "Epoch 21/150\n",
      "72/72 [==============================] - 0s 5ms/step - loss: 1.6343 - mae: 0.9823 - val_loss: 1.6636 - val_mae: 0.9963\n",
      "Epoch 22/150\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.5725 - mae: 0.9643 - val_loss: 1.6213 - val_mae: 0.9805\n",
      "Epoch 23/150\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.5200 - mae: 0.9473 - val_loss: 1.5893 - val_mae: 0.9790\n",
      "Epoch 24/150\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 1.4720 - mae: 0.9340 - val_loss: 1.5332 - val_mae: 0.9541\n",
      "Epoch 25/150\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 1.4217 - mae: 0.9191 - val_loss: 1.4870 - val_mae: 0.9452\n",
      "Epoch 26/150\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.3646 - mae: 0.9030 - val_loss: 1.4552 - val_mae: 0.9290\n",
      "Epoch 27/150\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.3229 - mae: 0.8901 - val_loss: 1.4145 - val_mae: 0.9246\n",
      "Epoch 28/150\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.2796 - mae: 0.8780 - val_loss: 1.3757 - val_mae: 0.9063\n",
      "Epoch 29/150\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.2391 - mae: 0.8641 - val_loss: 1.3363 - val_mae: 0.8937\n",
      "Epoch 30/150\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.1970 - mae: 0.8465 - val_loss: 1.3086 - val_mae: 0.8869\n",
      "Epoch 31/150\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 1.1583 - mae: 0.8374 - val_loss: 1.2714 - val_mae: 0.8690\n",
      "Epoch 32/150\n",
      "72/72 [==============================] - 0s 5ms/step - loss: 1.1203 - mae: 0.8186 - val_loss: 1.2429 - val_mae: 0.8602\n",
      "Epoch 33/150\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0834 - mae: 0.8092 - val_loss: 1.2127 - val_mae: 0.8471\n",
      "Epoch 34/150\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 1.0453 - mae: 0.7956 - val_loss: 1.1738 - val_mae: 0.8356\n",
      "Epoch 35/150\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0130 - mae: 0.7829 - val_loss: 1.1451 - val_mae: 0.8257\n",
      "Epoch 36/150\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.9799 - mae: 0.7705 - val_loss: 1.1182 - val_mae: 0.8182\n",
      "Epoch 37/150\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9512 - mae: 0.7596 - val_loss: 1.0900 - val_mae: 0.8019\n",
      "Epoch 38/150\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.9172 - mae: 0.7478 - val_loss: 1.0638 - val_mae: 0.7953\n",
      "Epoch 39/150\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8943 - mae: 0.7381 - val_loss: 1.0418 - val_mae: 0.7844\n",
      "Epoch 40/150\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.8679 - mae: 0.7278 - val_loss: 1.0135 - val_mae: 0.7779\n",
      "Epoch 41/150\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.8421 - mae: 0.7167 - val_loss: 0.9965 - val_mae: 0.7664\n",
      "Epoch 42/150\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.8204 - mae: 0.7078 - val_loss: 0.9759 - val_mae: 0.7641\n",
      "Epoch 43/150\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.7972 - mae: 0.6986 - val_loss: 0.9541 - val_mae: 0.7509\n",
      "Epoch 44/150\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.7754 - mae: 0.6889 - val_loss: 0.9405 - val_mae: 0.7435\n",
      "Epoch 45/150\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.7546 - mae: 0.6809 - val_loss: 0.9171 - val_mae: 0.7365\n",
      "Epoch 46/150\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.7343 - mae: 0.6722 - val_loss: 0.9001 - val_mae: 0.7298\n",
      "Epoch 47/150\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.7184 - mae: 0.6638 - val_loss: 0.8849 - val_mae: 0.7239\n",
      "Epoch 48/150\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.7013 - mae: 0.6567 - val_loss: 0.8757 - val_mae: 0.7247\n",
      "Epoch 49/150\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.6850 - mae: 0.6502 - val_loss: 0.8518 - val_mae: 0.7130\n",
      "Epoch 50/150\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.6698 - mae: 0.6423 - val_loss: 0.8414 - val_mae: 0.7115\n",
      "Epoch 51/150\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.6572 - mae: 0.6360 - val_loss: 0.8299 - val_mae: 0.6999\n",
      "Epoch 52/150\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.6439 - mae: 0.6281 - val_loss: 0.8244 - val_mae: 0.6984\n",
      "Epoch 53/150\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.6328 - mae: 0.6248 - val_loss: 0.8066 - val_mae: 0.6905\n",
      "Epoch 54/150\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.6183 - mae: 0.6168 - val_loss: 0.8024 - val_mae: 0.6889\n",
      "Epoch 55/150\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.6080 - mae: 0.6110 - val_loss: 0.7830 - val_mae: 0.6816\n",
      "Epoch 56/150\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.5979 - mae: 0.6080 - val_loss: 0.7753 - val_mae: 0.6784\n",
      "Epoch 57/150\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.5897 - mae: 0.6022 - val_loss: 0.7808 - val_mae: 0.6798\n",
      "Epoch 58/150\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.5816 - mae: 0.6000 - val_loss: 0.7587 - val_mae: 0.6710\n",
      "Epoch 59/150\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.5706 - mae: 0.5920 - val_loss: 0.7558 - val_mae: 0.6678\n",
      "Epoch 60/150\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.5633 - mae: 0.5887 - val_loss: 0.7478 - val_mae: 0.6655\n",
      "Epoch 61/150\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.5573 - mae: 0.5848 - val_loss: 0.7381 - val_mae: 0.6623\n",
      "Epoch 62/150\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.5498 - mae: 0.5821 - val_loss: 0.7309 - val_mae: 0.6585\n",
      "Epoch 63/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - 0s 2ms/step - loss: 0.5420 - mae: 0.5783 - val_loss: 0.7255 - val_mae: 0.6563\n",
      "Epoch 64/150\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.5359 - mae: 0.5746 - val_loss: 0.7221 - val_mae: 0.6559\n",
      "Epoch 65/150\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.5325 - mae: 0.5725 - val_loss: 0.7115 - val_mae: 0.6494\n",
      "Epoch 66/150\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.5230 - mae: 0.5685 - val_loss: 0.7107 - val_mae: 0.6482\n",
      "Epoch 67/150\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.5185 - mae: 0.5650 - val_loss: 0.7034 - val_mae: 0.6466\n",
      "Epoch 68/150\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.5115 - mae: 0.5594 - val_loss: 0.7181 - val_mae: 0.6526\n",
      "Epoch 69/150\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.5113 - mae: 0.5607 - val_loss: 0.6946 - val_mae: 0.6428\n",
      "Epoch 70/150\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.5031 - mae: 0.5587 - val_loss: 0.7010 - val_mae: 0.6430\n",
      "Epoch 71/150\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.4993 - mae: 0.5555 - val_loss: 0.6917 - val_mae: 0.6407\n",
      "Epoch 72/150\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.4957 - mae: 0.5530 - val_loss: 0.6859 - val_mae: 0.6371\n",
      "Epoch 73/150\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.4920 - mae: 0.5482 - val_loss: 0.6900 - val_mae: 0.6396\n",
      "Epoch 74/150\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.4872 - mae: 0.5488 - val_loss: 0.6834 - val_mae: 0.6359\n",
      "Epoch 75/150\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.4840 - mae: 0.5462 - val_loss: 0.6808 - val_mae: 0.6348\n",
      "Epoch 76/150\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.4798 - mae: 0.5433 - val_loss: 0.6748 - val_mae: 0.6307\n",
      "Epoch 77/150\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.4751 - mae: 0.5404 - val_loss: 0.6724 - val_mae: 0.6302\n",
      "Epoch 78/150\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.4720 - mae: 0.5392 - val_loss: 0.6798 - val_mae: 0.6332\n",
      "Epoch 79/150\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.4696 - mae: 0.5360 - val_loss: 0.6641 - val_mae: 0.6265\n",
      "Epoch 80/150\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.4666 - mae: 0.5360 - val_loss: 0.6633 - val_mae: 0.6262\n",
      "Epoch 81/150\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.4642 - mae: 0.5327 - val_loss: 0.6654 - val_mae: 0.6274\n",
      "Epoch 82/150\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.4592 - mae: 0.5305 - val_loss: 0.6659 - val_mae: 0.6268\n",
      "Epoch 83/150\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.4587 - mae: 0.5300 - val_loss: 0.6596 - val_mae: 0.6239\n",
      "Epoch 84/150\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.4529 - mae: 0.5267 - val_loss: 0.6673 - val_mae: 0.6296\n",
      "Epoch 85/150\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.4528 - mae: 0.5262 - val_loss: 0.6521 - val_mae: 0.6213\n",
      "Epoch 86/150\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.4498 - mae: 0.5252 - val_loss: 0.6527 - val_mae: 0.6204\n",
      "Epoch 87/150\n",
      "72/72 [==============================] - 0s 5ms/step - loss: 0.4455 - mae: 0.5237 - val_loss: 0.6568 - val_mae: 0.6233\n",
      "Epoch 88/150\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.4437 - mae: 0.5220 - val_loss: 0.6508 - val_mae: 0.6216\n",
      "Epoch 89/150\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.4419 - mae: 0.5195 - val_loss: 0.6496 - val_mae: 0.6203\n",
      "Epoch 90/150\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.4411 - mae: 0.5204 - val_loss: 0.6450 - val_mae: 0.6169\n",
      "Epoch 91/150\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.4364 - mae: 0.5174 - val_loss: 0.6471 - val_mae: 0.6191\n",
      "Epoch 92/150\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.4345 - mae: 0.5153 - val_loss: 0.6546 - val_mae: 0.6230\n",
      "Epoch 93/150\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.4333 - mae: 0.5172 - val_loss: 0.6400 - val_mae: 0.6161\n",
      "Epoch 94/150\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.4304 - mae: 0.5129 - val_loss: 0.6355 - val_mae: 0.6124\n",
      "Epoch 95/150\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.4297 - mae: 0.5136 - val_loss: 0.6338 - val_mae: 0.6122\n",
      "Epoch 96/150\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.4262 - mae: 0.5097 - val_loss: 0.6376 - val_mae: 0.6151\n",
      "Epoch 97/150\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.4236 - mae: 0.5103 - val_loss: 0.6340 - val_mae: 0.6118\n",
      "Epoch 98/150\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.4227 - mae: 0.5078 - val_loss: 0.6329 - val_mae: 0.6103\n",
      "Epoch 99/150\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.4204 - mae: 0.5072 - val_loss: 0.6320 - val_mae: 0.6113\n",
      "Epoch 100/150\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.4189 - mae: 0.5061 - val_loss: 0.6360 - val_mae: 0.6135\n",
      "Epoch 101/150\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.4179 - mae: 0.5041 - val_loss: 0.6353 - val_mae: 0.6126\n",
      "Epoch 102/150\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.4144 - mae: 0.5039 - val_loss: 0.6301 - val_mae: 0.6116\n",
      "Epoch 103/150\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.4136 - mae: 0.5041 - val_loss: 0.6277 - val_mae: 0.6087\n",
      "Epoch 104/150\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.4132 - mae: 0.5023 - val_loss: 0.6262 - val_mae: 0.6093\n",
      "Epoch 105/150\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.4109 - mae: 0.5005 - val_loss: 0.6217 - val_mae: 0.6063\n",
      "Epoch 106/150\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.4102 - mae: 0.5003 - val_loss: 0.6223 - val_mae: 0.6062\n",
      "Epoch 107/150\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.4067 - mae: 0.4978 - val_loss: 0.6262 - val_mae: 0.6099\n",
      "Epoch 108/150\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.4047 - mae: 0.4981 - val_loss: 0.6189 - val_mae: 0.6031\n",
      "Epoch 109/150\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.4030 - mae: 0.4967 - val_loss: 0.6150 - val_mae: 0.6019\n",
      "Epoch 110/150\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.4016 - mae: 0.4940 - val_loss: 0.6188 - val_mae: 0.6042\n",
      "Epoch 111/150\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.4005 - mae: 0.4943 - val_loss: 0.6239 - val_mae: 0.6067\n",
      "Epoch 112/150\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.3994 - mae: 0.4937 - val_loss: 0.6181 - val_mae: 0.6043\n",
      "Epoch 113/150\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.3970 - mae: 0.4934 - val_loss: 0.6170 - val_mae: 0.6018\n",
      "Epoch 114/150\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.3953 - mae: 0.4908 - val_loss: 0.6149 - val_mae: 0.6013\n",
      "Epoch 115/150\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.3932 - mae: 0.4906 - val_loss: 0.6236 - val_mae: 0.6084\n",
      "Epoch 116/150\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.3922 - mae: 0.4899 - val_loss: 0.6158 - val_mae: 0.6037\n",
      "Epoch 117/150\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.3913 - mae: 0.4875 - val_loss: 0.6204 - val_mae: 0.6052\n",
      "Epoch 118/150\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.3899 - mae: 0.4878 - val_loss: 0.6140 - val_mae: 0.6009\n",
      "Epoch 119/150\n",
      "72/72 [==============================] - 0s 5ms/step - loss: 0.3888 - mae: 0.4881 - val_loss: 0.6119 - val_mae: 0.5999\n",
      "Epoch 120/150\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.3875 - mae: 0.4860 - val_loss: 0.6062 - val_mae: 0.5972\n",
      "Epoch 121/150\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.3851 - mae: 0.4844 - val_loss: 0.6168 - val_mae: 0.6048\n",
      "Epoch 122/150\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.3822 - mae: 0.4818 - val_loss: 0.6201 - val_mae: 0.6055\n",
      "Epoch 123/150\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.3830 - mae: 0.4840 - val_loss: 0.6061 - val_mae: 0.5972\n",
      "Epoch 124/150\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.3801 - mae: 0.4810 - val_loss: 0.6140 - val_mae: 0.6000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 125/150\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.3800 - mae: 0.4803 - val_loss: 0.6107 - val_mae: 0.5997\n",
      "Epoch 126/150\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.3785 - mae: 0.4796 - val_loss: 0.6042 - val_mae: 0.5935\n",
      "Epoch 127/150\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.3773 - mae: 0.4786 - val_loss: 0.6112 - val_mae: 0.6002\n",
      "Epoch 128/150\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.3772 - mae: 0.4772 - val_loss: 0.6038 - val_mae: 0.5953\n",
      "Epoch 129/150\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.3744 - mae: 0.4781 - val_loss: 0.6124 - val_mae: 0.6012\n",
      "Epoch 130/150\n",
      "72/72 [==============================] - 0s 5ms/step - loss: 0.3724 - mae: 0.4770 - val_loss: 0.6037 - val_mae: 0.5958\n",
      "Epoch 131/150\n",
      "72/72 [==============================] - 0s 5ms/step - loss: 0.3713 - mae: 0.4732 - val_loss: 0.6042 - val_mae: 0.5947\n",
      "Epoch 132/150\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.3694 - mae: 0.4723 - val_loss: 0.6098 - val_mae: 0.5990\n",
      "Epoch 133/150\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.3697 - mae: 0.4740 - val_loss: 0.6083 - val_mae: 0.5977\n",
      "Epoch 134/150\n",
      "72/72 [==============================] - 0s 5ms/step - loss: 0.3682 - mae: 0.4740 - val_loss: 0.6080 - val_mae: 0.5978\n",
      "Epoch 135/150\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.3676 - mae: 0.4721 - val_loss: 0.6015 - val_mae: 0.5942\n",
      "Epoch 136/150\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.3656 - mae: 0.4715 - val_loss: 0.6071 - val_mae: 0.5993\n",
      "Epoch 137/150\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.3655 - mae: 0.4711 - val_loss: 0.6046 - val_mae: 0.5965\n",
      "Epoch 138/150\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.3641 - mae: 0.4697 - val_loss: 0.6006 - val_mae: 0.5939\n",
      "Epoch 139/150\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.3633 - mae: 0.4701 - val_loss: 0.6024 - val_mae: 0.5945\n",
      "Epoch 140/150\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.3613 - mae: 0.4679 - val_loss: 0.5962 - val_mae: 0.5902\n",
      "Epoch 141/150\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.3617 - mae: 0.4664 - val_loss: 0.5992 - val_mae: 0.5931\n",
      "Epoch 142/150\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.3597 - mae: 0.4667 - val_loss: 0.6057 - val_mae: 0.5963\n",
      "Epoch 143/150\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.3586 - mae: 0.4656 - val_loss: 0.6014 - val_mae: 0.5939\n",
      "Epoch 144/150\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.3565 - mae: 0.4646 - val_loss: 0.6016 - val_mae: 0.5924\n",
      "Epoch 145/150\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.3557 - mae: 0.4645 - val_loss: 0.5986 - val_mae: 0.5924\n",
      "Epoch 146/150\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.3559 - mae: 0.4649 - val_loss: 0.6026 - val_mae: 0.5924\n",
      "Epoch 147/150\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.3555 - mae: 0.4623 - val_loss: 0.6018 - val_mae: 0.5945\n",
      "Epoch 148/150\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.3535 - mae: 0.4621 - val_loss: 0.5949 - val_mae: 0.5899\n",
      "Epoch 149/150\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.3517 - mae: 0.4602 - val_loss: 0.6046 - val_mae: 0.5965\n",
      "Epoch 150/150\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.3511 - mae: 0.4632 - val_loss: 0.6024 - val_mae: 0.5931\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f995c555370>"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='mse', optimizer=RMSprop(0.0001), metrics=['mae'])\n",
    "model.fit(X_train, y_train, validation_split=0.3, epochs=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 0s 1ms/step - loss: 0.5967 - mae: 0.5941\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5966840982437134, 0.5940666198730469]"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.86321244e+00, 2.79100884e-01, 6.43267297e+00, 4.55236208e-02,\n",
       "       1.38148888e+02, 9.94053130e-01, 3.18971960e+00, 4.89457482e-01,\n",
       "       1.05131616e+01])"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.mean_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pred = np.around(pred)\n",
    "y_tes = list(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5269016697588126"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(np.around(pred), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf2.0] *",
   "language": "python",
   "name": "conda-env-tf2.0-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
